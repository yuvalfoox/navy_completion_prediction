# Install dependencies
%pip install -r ../requirements.txt

# ----------------------------------------
# Imports and parameters
# ----------------------------------------
from src.data.load_data import load_and_label
from src.features.engineer import engineer_features
from src.models.train import prepare_features, train_models, evaluate_model
from src.visualization.plots import plot_confusion_matrices, plot_roc_curves, plot_shap_summary
import pandas as pd

# Specify which stages to run: [1], [2], or both [1, 2]
stages = [1, 2]

# ----------------------------------------
# Helper: chronological split by assessment_counter
# ----------------------------------------
def split_by_counter(data, col='assessment_counter', train=0.6, val=0.2):
    max_val = data[col].max()
    train_idx = int(max_val * train)
    val_idx = int(max_val * (train + val))
    train = data[data[col] <= train_idx]
    val   = data[(data[col] > train_idx) & (data[col] <= val_idx)]
    test  = data[data[col] > val_idx]
    return train, val, test

# ----------------------------------------
# Core: run the full pipeline for one stage
# ----------------------------------------
def run_stage(stage):
    print(f"\n## Running pipeline for Stage {stage}\n")

    # 1. Load & label
    df = load_and_label('navy_assessments_v1.xlsx', stage=stage)
    print(f"Loaded data: {len(df)} records for Stage {stage}")

    # 2. Feature engineering
    df = engineer_features(df)
    print("Features engineered.")

    # 3. Chronological split
    train_df, val_df, test_df = split_by_counter(df)
    X_train, y_train = train_df.drop(columns=['target']), train_df['target']
    X_test,  y_test  = test_df.drop(columns=['target']),  test_df['target']
    print(f"Train/Test split: {len(X_train)} train, {len(X_test)} test")

    # 4. Feature selection & filtering
    X_train_sel = prepare_features(X_train, y_train)
    X_test_sel  = X_test[X_train_sel.columns]
    print(f"Selected {X_train_sel.shape[1]} features.")

    # 5. Model training
    lr, rf, ensemble = train_models(X_train_sel, y_train)

    # 6. Evaluation
    print(f"\n-- Evaluation for Stage {stage}: Logistic Regression --")
    evaluate_model(lr, X_test_sel, y_test)

    print(f"\n-- Evaluation for Stage {stage}: Random Forest --")
    evaluate_model(rf, X_test_sel, y_test)

    print(f"\n-- Evaluation for Stage {stage}: Ensemble --")
    evaluate_model(ensemble, X_test_sel, y_test)

    # 7. Visualizations
    models = {
        "Logistic Regression": lr,
        "Random Forest":       rf,
        "Ensemble":            ensemble
    }
    plot_confusion_matrices(models, X_test_sel, y_test)
    plot_roc_curves(models, X_test_sel, y_test)
    plot_shap_summary(rf, X_test_sel)

# ----------------------------------------
# Execute for each selected stage
# ----------------------------------------
for stage in stages:
    run_stage(stage)
